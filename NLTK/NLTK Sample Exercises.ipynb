{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> These are notes from http://nlpworkgroup.postach.io/ converted into a Jupyter Notebook. Original material by Justin Barber, notebook-ified by Sean Boisen. \n",
    "\n",
    "> To use this material, you must first do the following:\n",
    "* sudo easy_install pip         # Mac OS X\n",
    "* pip install NLTK\n",
    "* pip install requests\n",
    "\n",
    "> See http://nlpworkgroup.postach.io/ for installation directions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Sample Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simple examples of what you can do with NLP. Easy first, then moderately difficult, and then graphical snippets. Created on Nov 17, 2015 by Justin Barber."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOWNLOAD A PROJECT GUTENBERG TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# $ pip install requests\n",
    "import requests\n",
    "url = \"http://www.gutenberg.org/files/2554/2554.txt\"\n",
    "request = requests.get(url)\n",
    "crime_and_punishment = request.content\n",
    "# this is the whole book! just print the first 500 chars\n",
    "print crime_and_punishment[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORD TOKENIZE A TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "word_tokens = word_tokenize(crime_and_punishment)\n",
    "num_words = len(word_tokens)\n",
    "print(\"Number of words:\", num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTENCE TOKENIZE A TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "sent_tokens = sent_tokenize(crime_and_punishment)\n",
    "num_sents = len(sent_tokens)\n",
    "print(\"Number of sentences:\", num_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE A CONCORDANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import Text\n",
    "from nltk.corpus import brown\n",
    "tokens = brown.words('cg13')\n",
    "text = Text(tokens)\n",
    "concordance = text.concordance(\"sex\", lines=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTEXTUAL SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import Text\n",
    "from nltk.corpus import genesis\n",
    "tokens = genesis.words('english-web.txt')\n",
    "text = Text(tokens)\n",
    "print(\"Words that occur in contexts similar to the contexts 'fought' occurs in:\")\n",
    "text.similar(\"fought\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEMANTIC SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "bible = wordnet.synset('bible.n.01')\n",
    "book = wordnet.synset('book.n.01')\n",
    "scroll = wordnet.synset('scroll.n.02')\n",
    "scroll_bible = scroll.lowest_common_hypernyms(bible)\n",
    "book_bible = book.lowest_common_hypernyms(bible)\n",
    "print(\"Lowest common hypernym for scroll and bible:\", scroll_bible)\n",
    "print(\"Lowest common hypernym for book and bible:\", book_bible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART OF SPEECH TAGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "sentence = (\"In the beginning when God created the heavens and the earth, \"\n",
    "                        \"the earth was a formless void and darkness covered the face of \"\n",
    "                        \"the deep, while a wind from God swept over the face of the waters.\")\n",
    "tokens = word_tokenize(sentence)\n",
    "tagged_tokens = pos_tag(tokens)\n",
    "print('Tokens tagged with part of speech:', tagged_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROPOSITIONAL LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk import ResolutionProver\n",
    "from nltk.sem import Expression\n",
    "read_expr = Expression.fromstring\n",
    "assumpt1 = read_expr('man(socrates)')                # socrates is a man\n",
    "assumpt2 = read_expr('all x.(man(x) -> mortal(x))')  # for all x, if x is man, x is mortal\n",
    "goal = read_expr('mortal(socrates)')                 # socrates is mortal\n",
    "resolution = ResolutionProver().prove(goal, [assumpt1, assumpt2], verbose=True)\n",
    "print(\"Socrates is mortal:\", resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHUNKING NOUN PHRASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag, RegexpParser, word_tokenize\n",
    "# optional determiner (DT) followed by 0 or more adjectives (JJ) and then a noun (NN)\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "# tag tokens\n",
    "sentence = \"Better is a poor but wise youth than an old but foolish king.\"\n",
    "tokens = word_tokenize(sentence)\n",
    "tagged_tokens = pos_tag(tokens)\n",
    "# now chunk\n",
    "chunk_parser = RegexpParser(grammar)\n",
    "parsed = chunk_parser.parse(tagged_tokens)\n",
    "# graph the results\n",
    "parsed.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISPERSION PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# $ pip install matplotlib\n",
    "import nltk\n",
    "# if you haven't already downloaded the corpora\n",
    "# nltk.download() # choose corpora tab and select genesis and click download\n",
    "from nltk import Text\n",
    "from nltk.corpus import genesis\n",
    "tokens = genesis.words('english-kjv.txt')\n",
    "text = Text(tokens)\n",
    "text.dispersion_plot([\"God\", \"man\", \"woman\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
